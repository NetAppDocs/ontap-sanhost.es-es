---
sidebar: sidebar 
permalink: nvme_esxi_7.html 
keywords: nvme, esxi, ontap, nvme/fc, hypervisor 
summary: Describe cómo configurar NVMe-of para ESXi 7.x con ONTAP 
---
= Configuración de NVMe-of Host para ESXi 7.x con ONTAP
:toc: macro
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toc: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:toc-position: content




== Compatibilidad

* A partir de ONTAP 9.7, se admite NVMe over Fibre Channel (NVMe/FC) en las versiones VMware vSphere.
* A partir de las 7.0U3c, la función NVMe/TCP es compatible con el hipervisor ESXi.
* A partir de ONTAP 9.10.1, ONTAP admite la función NVMe/TCP.




== Funciones

* El host iniciador ESXi puede ejecutar tráfico NVMe/FC y FCP a través de los mismos puertos de adaptador. Consulte link:https://hwu.netapp.com/Home/Index["Hardware Universe"^] Para obtener una lista de controladoras y adaptadores de FC admitidos. Consulte link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^] para obtener la lista más actual de configuraciones y versiones compatibles.
* A partir de ONTAP 9.9.1 P3, la función NVMe/FC es compatible para ESXi 7.0 update 3.
* Para ESXi 7.0 y versiones posteriores, HPP (complemento de alto rendimiento) es el complemento predeterminado para dispositivos NVMe.




== Limitaciones conocidas

No se admiten las siguientes configuraciones:

* Asignación de RDM
* VVol




== Habilite NVMe/FC

. Compruebe la cadena del host ESXi NQN y verifique que coincide con la cadena de host NQN para el subsistema correspondiente en la cabina de ONTAP:
+
[listing]
----
# esxcli nvme  info get
Host NQN: nqn.2014-08.com.vmware:nvme:nvme-esx

# vserver nvme subsystem host show -vserver vserver_nvme
  Vserver Subsystem             Host NQN
  ------- ------------------- ----------------------------------------
  vserver_nvme ss_vserver_nvme nqn.2014-08.com.vmware:nvme:nvme-esx
----




=== Configure Broadcom/Emulex

. Para comprobar si la configuración es compatible con el controlador/firmware requerido, consulte link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^].
. Defina el parámetro del controlador lpfc `lpfc_enable_fc4_type=3` Para habilitar la compatibilidad con NVMe/FC en el `lpfc` driver y reinicie el host.



NOTE: A partir de la actualización 3 de vSphere 7.0, el `brcmnvmefc` el controlador ya no está disponible. Por lo tanto, la `lpfc` El controlador ahora incluye la funcionalidad NVMe over Fibre Channel (NVMe/FC) que se proporcionó anteriormente con el `brcmnvmefc` controlador.


NOTE: La `lpfc_enable_fc4_type=3` El parámetro está establecido de forma predeterminada para los adaptadores de la serie LPe35000. Debe ejecutar el siguiente comando para configurarlo manualmente para los adaptadores de las series LPe32000 y LPe31000.

[listing]
----
# esxcli system module parameters set -m lpfc -p lpfc_enable_fc4_type=3

#esxcli system module parameters list  -m lpfc | grep lpfc_enable_fc4_type
lpfc_enable_fc4_type              int     3      Defines what FC4 types are supported

#esxcli storage core adapter list
HBA Name  Driver   Link State  UID                                   Capabilities         Description
--------  -------  ----------  ------------------------------------  -------------------  -----------
vmhba1    lpfc     link-up     fc.200000109b95456f:100000109b95456f  Second Level Lun ID  (0000:86:00.0) Emulex Corporation Emulex LPe36000 Fibre Channel Adapter    FC HBA
vmhba2    lpfc     link-up     fc.200000109b954570:100000109b954570  Second Level Lun ID  (0000:86:00.1) Emulex Corporation Emulex LPe36000 Fibre Channel Adapter    FC HBA
vmhba64   lpfc     link-up     fc.200000109b95456f:100000109b95456f                       (0000:86:00.0) Emulex Corporation Emulex LPe36000 Fibre Channel Adapter   NVMe HBA
vmhba65   lpfc     link-up     fc.200000109b954570:100000109b954570                       (0000:86:00.1) Emulex Corporation Emulex LPe36000 Fibre Channel Adapter   NVMe HBA
----


=== Configuración de Marvell/QLogic

.Pasos
. Para comprobar si la configuración es compatible con el controlador/firmware requerido, consulte link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^].
. Ajuste la `qlnativefc` parámetro del conductor `ql2xnvmesupport=1` Para habilitar la compatibilidad con NVMe/FC en el `qlnativefc` driver y reinicie el host.
+
`# esxcfg-module -s 'ql2xnvmesupport=1' qlnativefc`

+

NOTE: La `qlnativefc` El parámetro de controlador está establecido de forma predeterminada para los adaptadores serie QLE 277x. Debe ejecutar el siguiente comando para establecerlo manualmente para los adaptadores serie QLE 277x.

+
[listing]
----
esxcfg-module -l | grep qlnativefc
qlnativefc               4    1912
----
. Compruebe si nvme está habilitado en el adaptador:
+
[listing]
----
  #esxcli storage core adapter list
HBA Name  Driver      Link State  UID                                   Capabilities         Description
--------  ----------  ----------  ------------------------------------  -------------------  -----------
 vmhba3    qlnativefc  link-up     fc.20000024ff1817ae:21000024ff1817ae  Second Level Lun ID  (0000:5e:00.0) QLogic Corp QLE2742 Dual Port 32Gb Fibre Channel to PCIe Adapter    FC Adapter
vmhba4    qlnativefc  link-up     fc.20000024ff1817af:21000024ff1817af  Second Level Lun ID  (0000:5e:00.1) QLogic Corp QLE2742 Dual Port 32Gb Fibre Channel to PCIe Adapter FC Adapter
vmhba64   qlnativefc  link-up     fc.20000024ff1817ae:21000024ff1817ae                       (0000:5e:00.0) QLogic Corp QLE2742 Dual Port 32Gb Fibre Channel to PCIe Adapter  NVMe FC Adapter
vmhba65   qlnativefc  link-up     fc.20000024ff1817af:21000024ff1817af                       (0000:5e:00.1) QLogic Corp QLE2742 Dual Port 32Gb Fibre Channel to PCIe Adapter  NVMe FC Adapter
----




== Valide NVMe/FC

. Compruebe que el adaptador NVMe/FC aparezca en el host ESXi:
+
[listing]
----
# esxcli nvme adapter list

Adapter  Adapter Qualified Name           Transport Type  Driver      Associated Devices
-------  -------------------------------  --------------  ----------  ------------------
vmhba64  aqn:qlnativefc:21000024ff1817ae  FC              qlnativefc
vmhba65  aqn:qlnativefc:21000024ff1817af  FC              qlnativefc
vmhba66  aqn:lpfc:100000109b579d9c 	      FC              lpfc
vmhba67  aqn:lpfc:100000109b579d9d 	      FC              lpfc

----
. Compruebe que los espacios de nombres NVMe/FC se hayan creado correctamente:
+
Los UUID en el siguiente ejemplo representan los dispositivos de espacio de nombres NVMe/FC.

+
[listing]
----
# esxcfg-mpath -b
uuid.5084e29a6bb24fbca5ba076eda8ecd7e : NVMe Fibre Channel Disk (uuid.5084e29a6bb24fbca5ba076eda8ecd7e)
   vmhba65:C0:T0:L1 LUN:1 state:active fc Adapter: WWNN: 20:00:34:80:0d:6d:72:69 WWPN: 21:00:34:80:0d:6d:72:69  Target: WWNN: 20:17:00:a0:98:df:e3:d1 WWPN: 20:2f:00:a0:98:df:e3:d1
   vmhba65:C0:T1:L1 LUN:1 state:active fc Adapter: WWNN: 20:00:34:80:0d:6d:72:69 WWPN: 21:00:34:80:0d:6d:72:69  Target: WWNN: 20:17:00:a0:98:df:e3:d1 WWPN: 20:1a:00:a0:98:df:e3:d1
   vmhba64:C0:T0:L1 LUN:1 state:active fc Adapter: WWNN: 20:00:34:80:0d:6d:72:68 WWPN: 21:00:34:80:0d:6d:72:68  Target: WWNN: 20:17:00:a0:98:df:e3:d1 WWPN: 20:18:00:a0:98:df:e3:d1
   vmhba64:C0:T1:L1 LUN:1 state:active fc Adapter: WWNN: 20:00:34:80:0d:6d:72:68 WWPN: 21:00:34:80:0d:6d:72:68  Target: WWNN: 20:17:00:a0:98:df:e3:d1 WWPN: 20:19:00:a0:98:df:e3:d1
----
+

NOTE: En ONTAP 9.7, el tamaño de bloque predeterminado para un espacio de nombres NVMe/FC es de 4K. El tamaño predeterminado no es compatible con ESXi. Por lo tanto, cuando se crean espacios de nombres para ESXi, debe configurar el tamaño de bloque de espacio de nombres como 512b. Puede hacer esto mediante el `vserver nvme namespace create` comando.

+
.Ejemplo
`vserver nvme namespace create -vserver vs_1 -path /vol/nsvol/namespace1 -size 100g -ostype vmware -block-size 512B`

+
Consulte la link:https://docs.netapp.com/ontap-9/index.jsp?topic=%2Fcom.netapp.doc.dot-cm-cmpr%2FGUID-5CB10C70-AC11-41C0-8C16-B4D0DF916E9B.html["Páginas manuales de comandos de ONTAP 9"^] para obtener más detalles.

. Compruebe el estado de las rutas ANA individuales de los dispositivos de espacio de nombres NVMe/FC respectivos:
+
[listing]
----
esxcli storage hpp path list -d uuid.5084e29a6bb24fbca5ba076eda8ecd7e
fc.200034800d6d7268:210034800d6d7268-fc.201700a098dfe3d1:201800a098dfe3d1-uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Runtime Name: vmhba64:C0:T0:L1
   Device: uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Device Display Name: NVMe Fibre Channel Disk (uuid.5084e29a6bb24fbca5ba076eda8ecd7e)
   Path State: active
   Path Config: {TPG_id=0,TPG_state=AO,RTP_id=0,health=UP}

fc.200034800d6d7269:210034800d6d7269-fc.201700a098dfe3d1:201a00a098dfe3d1-uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Runtime Name: vmhba65:C0:T1:L1
   Device: uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Device Display Name: NVMe Fibre Channel Disk (uuid.5084e29a6bb24fbca5ba076eda8ecd7e)
   Path State: active
   Path Config: {TPG_id=0,TPG_state=AO,RTP_id=0,health=UP}

fc.200034800d6d7269:210034800d6d7269-fc.201700a098dfe3d1:202f00a098dfe3d1-uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Runtime Name: vmhba65:C0:T0:L1
   Device: uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Device Display Name: NVMe Fibre Channel Disk (uuid.5084e29a6bb24fbca5ba076eda8ecd7e)
   Path State: active unoptimized
   Path Config: {TPG_id=0,TPG_state=ANO,RTP_id=0,health=UP}

fc.200034800d6d7268:210034800d6d7268-fc.201700a098dfe3d1:201900a098dfe3d1-uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Runtime Name: vmhba64:C0:T1:L1
   Device: uuid.5084e29a6bb24fbca5ba076eda8ecd7e
   Device Display Name: NVMe Fibre Channel Disk (uuid.5084e29a6bb24fbca5ba076eda8ecd7e)
   Path State: active unoptimized
   Path Config: {TPG_id=0,TPG_state=ANO,RTP_id=0,health=UP}
----




== Configure NVMe/TCP

A partir del 7.0U3c, se cargarán de forma predeterminada los módulos NVMe/TCP necesarios. Para configurar la red y el adaptador NVMe/TCP, consulte la documentación de VMware vSphere.



== Valide NVMe/TCP

.Pasos
. Compruebe el estado del adaptador NVMe/TCP.
+
[listing]
----
[root@R650-8-45:~] esxcli nvme adapter list
Adapter    Adapter Qualified Name
--------- -------------------------------
vmhba64    aqn:nvmetcp:34-80-0d-30-ca-e0-T
vmhba65    aqn:nvmetc:34-80-13d-30-ca-e1-T
list
Transport Type   Driver   Associated Devices
---------------  -------  ------------------
TCP              nvmetcp    vmnzc2
TCP              nvmetcp    vmnzc3
----
. Para enumerar las conexiones NVMe/TCP, utilice el siguiente comando:
+
[listing]
----
[root@R650-8-45:~] esxcli nvme controller list
Name
-----------
nqn.1992-08.com.netapp:sn.5e347cf68e0511ec9ec2d039ea13e6ed:subsystem.vs_name_tcp_ss#vmhba64#192.168.100.11:4420
nqn.1992-08.com.netapp:sn.5e347cf68e0511ec9ec2d039ea13e6ed:subsystem.vs_name_tcp_ss#vmhba64#192.168.101.11:4420
Controller Number  Adapter   Transport Type   IS Online
----------------- ---------  ---------------  ---------
1580              vmhba64    TCP              true
1588              vmhba65    TCP              true

----
. Para enumerar el número de rutas a un espacio de nombres NVMe, utilice el siguiente comando:
+
[listing]
----
[root@R650-8-45:~] esxcli storage hpp path list -d uuid.400bf333abf74ab8b96dc18ffadc3f99
tcp.vmnic2:34:80:Od:30:ca:eo-tcp.unknown-uuid.400bf333abf74ab8b96dc18ffadc3f99
   Runtime Name: vmhba64:C0:T0:L3
   Device: uuid.400bf333abf74ab8b96dc18ffadc3f99
   Device Display Name: NVMe TCP Disk (uuid.400bf333abf74ab8b96dc18ffadc3f99)
   Path State: active unoptimized
   Path config: {TPG_id=0,TPG_state=ANO,RTP_id=0,health=UP}

tcp.vmnic3:34:80:Od:30:ca:el-tcp.unknown-uuid.400bf333abf74ab8b96dc18ffadc3f99
   Runtime Name: vmhba65:C0:T1:L3
   Device: uuid.400bf333abf74ab8b96dc18ffadc3f99
   Device Display Name: NVMe TCP Disk (uuid.400bf333abf74ab8b96dc18ffadc3f99)
   Path State: active
   Path config: {TPG_id=0,TPG_state=AO,RTP_id=0,health=UP}
----




== Problema conocido

[cols="10,30,30"]
|===
| ID de error de NetApp | Título | Solución alternativa 


| link:https://mysupport.netapp.com/site/bugs-online/product/ONTAP/BURT/1420654["1420654"^] | Nodo de ONTAP no operativo cuando se utiliza el protocolo NVMe/FC con la versión 9.9.1 de ONTAP | Compruebe y rectifique los problemas de red en la estructura de host. Si esto no sirve de ayuda, actualice a un parche que solucione este problema. 
|===


== Enlaces relacionados

link:https://docs.netapp.com/us-en/netapp-solutions/virtualization/vsphere_ontap_ontap_for_vsphere.html["TR-4597-VMware vSphere con ONTAP"^]
link:https://kb.vmware.com/s/article/2031038["Compatibilidad de VMware vSphere 5.x, 6.x y 7.x con MetroCluster de NetApp (2031038)"^]
link:https://kb.vmware.com/s/article/83370["Compatibilidad de VMware vSphere 6.x y 7.x con NetApp® SnapMirror® Business Continuity (SM-BC)"^]
