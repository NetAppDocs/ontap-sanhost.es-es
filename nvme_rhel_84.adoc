---
sidebar: sidebar 
permalink: nvme_rhel_84.html 
keywords: nvme, linux, rhel, red hat, enterprise 
summary: Cómo configurar NVMe-of Host para RHEL 8.4 con ONTAP 
---
= Configuración del host NVMe-of para RHEL 8.4 con ONTAP
:toc: macro
:hardbreaks:
:toclevels: 1
:allow-uri-read: 
:toc: 
:toclevels: 1
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./media/
:source-highlighter: highlighter.js
:toc-position: content




== Compatibilidad

RHEL 8.4 admite NVMe over Fabrics o NVMe-of (incluidos NVMe/FC y otros transportes) con ANA (acceso de espacio de nombres asimétrico). ANA es el equivalente ALUA en el entorno NVMe-of y actualmente se implementa con NVMe multivía en el kernel. Los detalles para habilitar NVMe-of con NVMe multivía en el kernel mediante ANA en RHEL 8.4 y ONTAP, ya que el destino se ha documentado aquí.


NOTE: Puede utilizar los ajustes de configuración que se proporcionan en este documento para configurar los clientes de cloud conectados a. link:https://docs.netapp.com/us-en/cloud-manager-cloud-volumes-ontap/index.html["Cloud Volumes ONTAP"^] y.. link:https://docs.netapp.com/us-en/cloud-manager-fsx-ontap/index.html["Amazon FSX para ONTAP"^].



== Funciones

* Iniciando RHEL 8.2, `nvme-fc auto-connect` los scripts se incluyen en el nativo `nvme-cli` paquete. Puede confiar en estas secuencias de comandos de conexión automática nativas en lugar de tener que instalar las secuencias de comandos de conexión automática proporcionadas por el proveedor externo.
* A partir de RHEL 8.2, un nativo `udev` la regla ya se proporciona como parte de la `nvme-cli` Paquete que permite el equilibrio de carga por turnos para NVMe multivía. No es necesario crear esta regla de forma manual ya (como se hizo en RHEL 8.1).
* A partir de RHEL 8.2, es posible ejecutar el tráfico NVMe y SCSI en el mismo host coexistente. De hecho, se espera que sea la configuración de host instalada habitualmente para los clientes. Por lo tanto, para SCSI, puede configurar `dm-multipath` Como es habitual en LUN de SCSI, que dan como resultado `mpath` Dispositivos, mientras que NVMe multivía puede utilizarse para configurar dispositivos multivía NVMe-of en el host.
* A partir de RHEL 8.2, el complemento de NetApp se encuentra en la versión nativa `nvme-cli` El paquete puede mostrar detalles de la ONTAP, así como los espacios de nombres ONTAP.




== Limitaciones conocidas

* Para RHEL 8.4, la función multivía de NVMe en el kernel sigue deshabilitada de forma predeterminada. Por lo tanto, debe habilitarla manualmente.
* NVMe/TCP en RHEL 8.4 sigue siendo una función de vista previa de la tecnología debido a problemas abiertos. Consulte la https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/8.4_release_notes/index#technology-preview_file-systems-and-storage["Notas de la versión de RHEL 8.4"^] para obtener más detalles.




== Requisitos de configuración

Consulte la link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^] para obtener información precisa sobre las configuraciones compatibles.



== Habilite NVMe multivía en el kernel

. Instale RHEL 8.4 GA en el servidor. Una vez finalizada la instalación, compruebe que está ejecutando el kernel RHEL 8.4 GA especificado. Consulte link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^] para obtener la lista más actual de versiones compatibles.
. Una vez finalizada la instalación, compruebe que está ejecutando el kernel RHEL 8.4 especificado. Consulte link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^] para obtener la lista más actual de versiones compatibles.
+
Ejemplo:

+
[listing]
----
# uname -r
4.18.0-305.el8.x86_64
----
. Instale el `nvme-cli` paquete:
+
Ejemplo:

+
[listing]
----
# rpm -qa|grep nvme-cli
nvme-cli-1.12-3.el8.x86_64
----
. Habilitar multivía en el kernel NVMe:
+
[listing]
----
# grubby --args=nvme_core.multipath=Y --update-kernel /boot/vmlinuz-4.18.0-305.el8.x86_64
----
. En el host, compruebe la cadena NQN del host en `/etc/nvme/hostnqn` Y verifique que coincida con la cadena del host NQN para el subsistema correspondiente en la cabina de ONTAP. Ejemplo:
+
[listing]
----

# cat /etc/nvme/hostnqn
nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1
::> vserver nvme subsystem host show -vserver vs_fcnvme_141
Vserver     Subsystem       Host NQN
----------- --------------- ----------------------------------------------------------
vs_fcnvme_14 nvme_141_1     nqn.2014-08.org.nvmexpress:uuid:9ed5b327-b9fc-4cf5-97b3-1b5d986345d1

----
+

NOTE: Si las cadenas del host NQN no coinciden, se debe usar `vserver modify` Comando para actualizar la cadena NQN del host en el subsistema NVMe de ONTAP correspondiente para que coincidan con la cadena NQN del host `/etc/nvme/hostnqn` en el host.

. Reinicie el host.
+
[NOTE]
====
Si piensa ejecutar tráfico coexistente NVMe y SCSI en el mismo host, se recomienda usar la multivía en el kernel NVMe para espacios de nombres de ONTAP y dm-multipath para las LUN de ONTAP respectivamente. Esto significa que los espacios de nombres ONTAP deben excluirse de dm-multipath para evitar que dm-multipath reclamen estos dispositivos de espacio de nombres. Esto se puede hacer agregando la configuración enable_Foreign a la `/etc/multipath.conf` archivo:

[listing]
----
# cat /etc/multipath.conf
defaults {
        enable_foreign     NONE
}
----
====
. Reinicie el daemon multipathd ejecutando un `systemctl restart multipathd` comando para permitir que la nueva configuración surta efecto.




== Configure NVMe/FC



=== Broadcom/Emulex

. Compruebe que está utilizando el adaptador compatible. Consulte link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^] para obtener la lista más actual de adaptadores compatibles.
+
[listing]
----
# cat /sys/class/scsi_host/host*/modelname
LPe32002-M2
LPe32002-M2
# cat /sys/class/scsi_host/host*/modeldesc
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
Emulex LightPulse LPe32002-M2 2-Port 32Gb Fibre Channel Adapter
----
. Compruebe que está utilizando el firmware de Broadcom lpfc y el controlador de bandeja de entrada recomendados. Consulte link:https://mysupport.netapp.com/matrix/["Matriz de interoperabilidad de NetApp"^] para obtener la lista más actual de versiones de firmware y controladores de adaptador compatibles.
+
[listing]
----
# cat /sys/class/scsi_host/host*/fwrev
12.8.340.8, sli-4:2:c
12.8.340.8, sli-4:2:c
# cat /sys/module/lpfc/version
0:12.8.0.5
----
. Compruebe que `lpfc_enable_fc4_type` se establece en 3
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_enable_fc4_type
3
----
. Compruebe que los puertos iniciador están en funcionamiento y que puede ver las LIF de destino.
+
[listing, subs="+quotes"]
----
# cat /sys/class/fc_host/host*/port_name
0x100000109b1c1204
0x100000109b1c1205
# cat /sys/class/fc_host/host*/port_state
Online
Online
# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
XRI Dist lpfc0 Total 6144 IO 5894 ELS 250
*NVME LPORT lpfc0 WWPN x100000109b1c1204 WWNN x200000109b1c1204 DID x011d00 ONLINE*
*NVME RPORT WWPN x203800a098dfdd91 WWNN x203700a098dfdd91 DID x010c07 TARGET DISCSRVC ONLINE*
*NVME RPORT WWPN x203900a098dfdd91 WWNN x203700a098dfdd91 DID x011507 TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 0000000f78 Cmpl 0000000f78 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002fe29bba Issue 000000002fe29bc4 OutIO 000000000000000a
abort 00001bc7 noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001e15 Err 0000d906
NVME Initiator Enabled
XRI Dist lpfc1 Total 6144 IO 5894 ELS 250
*NVME LPORT lpfc1 WWPN x100000109b1c1205 WWNN x200000109b1c1205 DID x011900 ONLINE
NVME RPORT WWPN x203d00a098dfdd91 WWNN x203700a098dfdd91 DID x010007 TARGET DISCSRVC ONLINE
NVME RPORT WWPN x203a00a098dfdd91 WWNN x203700a098dfdd91 DID x012a07 TARGET DISCSRVC ONLINE*
NVME Statistics
LS: Xmt 0000000fa8 Cmpl 0000000fa8 Abort 00000000
LS XMIT: Err 00000000 CMPL: xb 00000000 Err 00000000
Total FCP Cmpl 000000002e14f170 Issue 000000002e14f17a OutIO 000000000000000a
abort 000016bb noxri 00000000 nondlp 00000000 qdepth 00000000 wqerr 00000000 err 00000000
FCP CMPL: xb 00001f50 Err 0000d9f8
----




==== Habilitar tamaño de I/o de 1 MB (opcional)

ONTAP informa de UN MDT (Tamaño de transferencia MAX Data) de 8 en los datos de identificación del controlador, lo que significa que el tamaño máximo de la solicitud de E/S debe ser de hasta 1 MB. Sin embargo, para emitir solicitudes de I/o de tamaño 1 MB para el host NVMe/FC de Broadcom, el parámetro lpfc `lpfc_sg_seg_cnt` también se debe hacer una bontap de hasta 256 desde el valor predeterminado de 64. Utilice las siguientes instrucciones para ello:

. Añada el valor `256` en las respectivas `modprobe lpfc.conf` archivo:
+
[listing]
----
# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_sg_seg_cnt=256
----
. Ejecute un `dracut -f` y reinicie el host.
. Tras reiniciar, compruebe que se ha aplicado el ajuste anterior comprobando el correspondiente `sysfs` valor:
+
[listing]
----
# cat /sys/module/lpfc/parameters/lpfc_sg_seg_cnt
256
----
+
Ahora el host FC-NVMe de Broadcom debe enviar hasta solicitudes de I/o de 1 MB en los dispositivos de espacio de nombres de ONTAP.





=== Marvell/QLogic

La bandeja de entrada nativa `qla2xxx` El controlador incluido en el kernel RHEL 8.4 GA tiene las últimas correcciones previas que son esenciales para la compatibilidad con ONTAP.

. Compruebe que está ejecutando las versiones de firmware y controlador del adaptador compatibles mediante el siguiente comando:
+
[listing]
----
# cat /sys/class/fc_host/host*/symbolic_name
QLE2742 FW:v9.06.02 DVR:v10.02.00.104-k
QLE2742 FW:v9.06.02 DVR:v10.02.00.104-k
----
. Verificación `ql2xnvmeenable` Is set que permite que el adaptador Marvell funcione como iniciador de NVMe/FC mediante el siguiente comando:
+
[listing]
----
# cat /sys/module/qla2xxx/parameters/ql2xnvmeenable
1
----




== Configure NVMe/TCP

A diferencia de NVMe/FC, NVMe/TCP no tiene una funcionalidad de conexión automática. Esto manifiesta dos limitaciones principales en el host NVMe/TCP de Linux:

* *No hay reconexión automática después de que las rutas se restablezcan* NVMe/TCP no puede volver a conectarse automáticamente a una ruta que se reinstala más allá de la predeterminada `ctrl-loss-tmo` temporizador de 10 minutos después de una ruta hacia abajo.
* *Sin conexión automática durante el arranque del host* NVMe/TCP no se puede conectar automáticamente durante el arranque del host también.


Es necesario configurar el periodo de reintento para eventos de conmutación por error en al menos 30 minutos para evitar los tiempos de espera. Puede aumentar el período de reintento aumentando el valor del temporizador ctrl_loss_tmo. A continuación se muestran los detalles:

.Pasos
. Compruebe si el puerto iniciador puede recuperar los datos de la página de registro de detección en las LIF NVMe/TCP admitidas:
+
[listing]
----
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.51
Discovery Log Number of Records 10, Generation counter 119
=====Discovery Log Entry 0======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 0
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_1
traddr: 192.168.2.56
sectype: none
=====Discovery Log Entry 1======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 1
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_1
traddr: 192.168.1.51
sectype: none
=====Discovery Log Entry 2======
trtype: tcp
adrfam: ipv4
subtype: nvme subsystem
treq: not specified
portid: 0
trsvcid: 4420
subnqn: nqn.1992-08.com.netapp:sn.56e362e9bb4f11ebbaded039ea165abc:subsystem.nvme_118_tcp_2
traddr: 192.168.2.56
sectype: none
...
----
. Compruebe que otros combinados LIF iniciador-objetivo NVMe/TCP pueden recuperar correctamente los datos de la página de registro de detección. Por ejemplo:
+
[listing]
----
# nvme discover -t tcp -w 192.168.1.8 -a 192.168.1.52
# nvme discover -t tcp -w 192.168.2.9 -a 192.168.2.56
# nvme discover -t tcp -w 192.168.2.9 -a 192.168.2.57
----
. Ejecución `nvme connect-all` Command entre todas las LIF de iniciador NVMe/TCP admitidas en los nodos. Asegúrese de establecer un valor más largo `ctrl_loss_tmo` período de reintento del temporizador (por ejemplo, 30 minutos, que se puede establecer a través de `-l 1800`) durante la conexión-todo para que vuelva a intentarlo durante un período más largo en caso de una pérdida de ruta. Por ejemplo:
+
[listing]
----
# nvme connect-all -t tcp -w 192.168.1.8 -a 192.168.1.51 -l 1800
# nvme connect-all -t tcp -w 192.168.1.8 -a 192.168.1.52 -l 1800
# nvme connect-all -t tcp -w 192.168.2.9 -a 192.168.2.56 -l 1800
# nvme connect-all -t tcp -w 192.168.2.9 -a 192.168.2.57 -l 1800
----




== Valide NVMe-of

. Compruebe que el acceso multivía de NVMe en el kernel esté habilitado realmente mediante la comprobación:
+
[listing]
----
# cat /sys/module/nvme_core/parameters/multipath
Y
----
. Compruebe que la configuración de NVMe-of adecuada (como, `model` establezca en `NetApp ONTAP Controller` y equilibrio de carga `iopolicy` establezca en `round-robin`) Para los respectivos espacios de nombres ONTAP se reflejan correctamente en el host:
+
[listing]
----
# cat /sys/class/nvme-subsystem/nvme-subsys*/model
NetApp ONTAP Controller
NetApp ONTAP Controller

# cat /sys/class/nvme-subsystem/nvme-subsys*/iopolicy
round-robin
round-robin
----
. Compruebe que los espacios de nombres de ONTAP se reflejan correctamente en el host. Por ejemplo:
+
[listing]
----
# nvme list
Node           SN                    Model                   Namespace
------------   --------------------- ---------------------------------
/dev/nvme0n1   81CZ5BQuUNfGAAAAAAAB  NetApp ONTAP Controller   1

Usage                Format         FW Rev
-------------------  -----------    --------
85.90 GB / 85.90 GB  4 KiB + 0 B    FFFFFFFF
----
+
Otro ejemplo:

+
[listing]
----
# nvme list
Node           SN                    Model                   Namespace
------------   --------------------- ---------------------------------
/dev/nvme0n1   81CYrBQuTHQFAAAAAAAC  NetApp ONTAP Controller   1

Usage                Format         FW Rev
-------------------  -----------    --------
85.90 GB / 85.90 GB  4 KiB + 0 B    FFFFFFFF
----
. Compruebe que el estado de la controladora de cada ruta sea activo y que tenga el estado de ANA adecuado. Por ejemplo:
+
[listing, subs="+quotes"]
----
# nvme list-subsys /dev/nvme1n1
nvme-subsys1 - NQN=nqn.1992-08.com.netapp:sn.04ba0732530911ea8e8300a098dfdd91:subsystem.nvme_145_1
\
+- nvme2 fc traddr=nn-0x208100a098dfdd91:pn-0x208200a098dfdd91 host_traddr=nn-0x200000109b579d5f:pn-0x100000109b579d5f live *non-optimized*
+- nvme3 fc traddr=nn-0x208100a098dfdd91:pn-0x208500a098dfdd91 host_traddr=nn-0x200000109b579d5e:pn-0x100000109b579d5e live *non-optimized*
+- nvme4 fc traddr=nn-0x208100a098dfdd91:pn-0x208400a098dfdd91 host_traddr=nn-0x200000109b579d5e:pn-0x100000109b579d5e live *optimized*
+- nvme6 fc traddr=nn-0x208100a098dfdd91:pn-0x208300a098dfdd91 host_traddr=nn-0x200000109b579d5f:pn-0x100000109b579d5f live *optimized*
----
+
Otro ejemplo:

+
[listing, subs="+quotes"]
----
#nvme list-subsys /dev/nvme0n1
nvme-subsys0 - NQN=nqn.1992-08.com.netapp:sn.37ba7d9cbfba11eba35dd039ea165514:subsystem.nvme_114_tcp_1
\
+- nvme0 tcp traddr=192.168.2.36 trsvcid=4420 host_traddr=192.168.1.4 live *optimized*
+- nvme1 tcp traddr=192.168.1.31 trsvcid=4420 host_traddr=192.168.1.4 live *optimized*
+- nvme10 tcp traddr=192.168.2.37 trsvcid=4420 host_traddr=192.168.1.4 live *non-optimized*
+- nvme11 tcp traddr=192.168.1.32 trsvcid=4420 host_traddr=192.168.1.4 live *non-optimized*
+- nvme20 tcp traddr=192.168.2.36 trsvcid=4420 host_traddr=192.168.2.5 live *optimized*
+- nvme21 tcp traddr=192.168.1.31 trsvcid=4420 host_traddr=192.168.2.5 live *optimized*
+- nvme30 tcp traddr=192.168.2.37 trsvcid=4420 host_traddr=192.168.2.5 live *non-optimized*
+- nvme31 tcp traddr=192.168.1.32 trsvcid=4420 host_traddr=192.168.2.5 live *non-optimized*
----
. Confirmar que el complemento de NetApp muestra los valores adecuados para cada dispositivo de espacio de nombres ONTAP. Por ejemplo:
+
[listing]
----
# nvme netapp ontapdevices -o column
Device       Vserver          Namespace Path
---------    -------          --------------------------------------------------
/dev/nvme1n1 vserver_fcnvme_145 /vol/fcnvme_145_vol_1_0_0/fcnvme_145_ns

NSID  UUID                                   Size
----  ------------------------------         ------
1      23766b68-e261-444e-b378-2e84dbe0e5e1  85.90GB


# nvme netapp ontapdevices -o json
{
"ONTAPdevices" : [
     {
       "Device" : "/dev/nvme1n1",
       "Vserver" : "vserver_fcnvme_145",
       "Namespace_Path" : "/vol/fcnvme_145_vol_1_0_0/fcnvme_145_ns",
       "NSID" : 1,
       "UUID" : "23766b68-e261-444e-b378-2e84dbe0e5e1",
       "Size" : "85.90GB",
       "LBA_Data_Size" : 4096,
       "Namespace_Size" : 20971520
     }
  ]
}
----
+
Otro ejemplo:

+
[listing]
----
# nvme netapp ontapdevices -o column
Device       Vserver          Namespace Path
---------    -------          --------------------------------------------------
/dev/nvme0n1 vs_tcp_114       /vol/tcpnvme_114_1_0_1/tcpnvme_114_ns

NSID  UUID                                   Size
----  ------------------------------         ------
1      a6aee036-e12f-4b07-8e79-4d38a9165686  85.90GB


# nvme netapp ontapdevices -o json
{
     "ONTAPdevices" : [
     {
          "Device" : "/dev/nvme0n1",
           "Vserver" : "vs_tcp_114",
          "Namespace_Path" : "/vol/tcpnvme_114_1_0_1/tcpnvme_114_ns",
          "NSID" : 1,
          "UUID" : "a6aee036-e12f-4b07-8e79-4d38a9165686",
          "Size" : "85.90GB",
          "LBA_Data_Size" : 4096,
          "Namespace_Size" : 20971520
       }
  ]

}
----




== Resolución de problemas

Antes de empezar a solucionar cualquier fallo de NVMe/FC, asegúrese de ejecutar una configuración que cumpla con las especificaciones de IMT y siga estos pasos para depurar cualquier problema en el lado del host.



=== LPFC Verbose Logging

. Puede ajustar la `lpfc_log_verbose` Configuración del controlador en cualquiera de los siguientes valores para registrar los eventos de NVMe/FC:
+
[listing]
----

#define LOG_NVME 0x00100000 /* NVME general events. */
#define LOG_NVME_DISC 0x00200000 /* NVME Discovery/Connect events. */
#define LOG_NVME_ABTS 0x00400000 /* NVME ABTS events. */
#define LOG_NVME_IOERR 0x00800000 /* NVME IO Error events. */

----
. Después de establecer cualquiera de estos valores, ejecute `dracut-f` para volver a crear el `initramfs` y reiniciar el host.
. Tras reiniciar, compruebe la configuración:
+
[listing]
----

# cat /etc/modprobe.d/lpfc.conf
options lpfc lpfc_log_verbose=0xf00083

# cat /sys/module/lpfc/parameters/lpfc_log_verbose
15728771
----




=== Qla2xxx Registro de Verbose

No hay ningún registro qla2xxx específico similar para NVMe/FC al controlador lpfc. Por lo tanto, puede establecer el nivel de registro general qla2xxx mediante los pasos siguientes:

. Añada el `ql2xextended_error_logging=0x1e400000` valor para el correspondiente `modprobe qla2xxx conf` archivo.
. Vuelva a crear el `initramfs` ejecutando `dracut -f` reinicie el host.
. Después de reiniciar, compruebe que el registro detallado se ha aplicado de la siguiente forma:
+
[listing]
----
# cat /etc/modprobe.d/qla2xxx.conf
options qla2xxx ql2xnvmeenable=1 ql2xextended_error_logging=0x1e400000
# cat /sys/module/qla2xxx/parameters/ql2xextended_error_logging
507510784
----




=== Errores y soluciones alternativas comunes de nvme-cli

Los errores mostrados por `nvme-cli` durante la detección nvme, las operaciones de nvme connect o nvme connect-all y las soluciones alternativas se muestran en la siguiente tabla:

[cols="20, 20, 50"]
|===
| Errores mostrados por `nvme-cli` | Causa probable | Solución alternativa 


| `Failed to write to /dev/nvme-fabrics: Invalid argument` | Sintaxis incorrecta | Asegúrese de utilizar la sintaxis correcta de los comandos nvme anteriores. 


| `Failed to write to /dev/nvme-fabrics: No such file or directory` | Varios problemas podrían desencadenarlo. La transferencia de argumentos incorrectos a los comandos nvme es una de las causas comunes.  a| 
* Asegúrese de haber pasado los argumentos correctos (como, una cadena WWNN, una cadena WWPN correcta y otros) a los comandos.
* Si los argumentos son correctos, pero sigue viendo este error, compruebe si `/sys/class/scsi_host/host*/nvme_info` La salida es correcta, el iniciador NVMe que se muestra como `Enabled`, Y las LIF de destino NVMe/FC se muestran correctamente aquí bajo las secciones de puertos remotos. Ejemplo:
+
[listing]
----

# cat /sys/class/scsi_host/host*/nvme_info
NVME Initiator Enabled
NVME LPORT lpfc0 WWPN x10000090fae0ec9d WWNN x20000090fae0ec9d DID x012000 ONLINE
NVME RPORT WWPN x200b00a098c80f09 WWNN x200a00a098c80f09 DID x010601 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000000000006 Cmpl 0000000000000006
FCP: Rd 0000000000000071 Wr 0000000000000005 IO 0000000000000031
Cmpl 00000000000000a6 Outstanding 0000000000000001
NVME Initiator Enabled
NVME LPORT lpfc1 WWPN x10000090fae0ec9e WWNN x20000090fae0ec9e DID x012400 ONLINE
NVME RPORT WWPN x200900a098c80f09 WWNN x200800a098c80f09 DID x010301 TARGET DISCSRVC ONLINE
NVME Statistics
LS: Xmt 0000000000000006 Cmpl 0000000000000006
FCP: Rd 0000000000000073 Wr 0000000000000005 IO 0000000000000031
Cmpl 00000000000000a8 Outstanding 0000000000000001
----
* Si las LIF de destino no se muestran como arriba en la salida nvme_info, compruebe la `/var/log/messages` y.. `dmesg` Genere cualquier error sospechoso de NVMe/FC, y corrija la salida según corresponda.




| `No discovery log entries to fetch`  a| 
Normalmente se ve si la `/etc/nvme/hostnqn` No se ha añadido la cadena al subsistema correspondiente en la cabina de NetApp o una incorrecta `hostnqn` la cadena se ha agregado al subsistema correspondiente.
 a| 
Asegúrese de que el sistema es exacto `/etc/nvme/hostnqn` La cadena se añade al subsistema correspondiente en la cabina de NetApp (compruebe mediante la `vserver nvme subsystem host show` ).



| `Failed to write to /dev/nvme-fabrics: Operation already in progress`  a| 
Se ve si las asociaciones de controladores o la operación especificada ya se han creado o se está creando. Esto podría suceder como parte de los scripts de conexión automática instalados anteriormente.
 a| 
Ninguno. Para `nvme discover`, intente ejecutar este comando después de un tiempo. Para `nvme connect` y.. `connect-all`, ejecute el `nvme list` comando para verificar que los dispositivos de espacio de nombres ya se han creado y se muestran en el host.

|===


=== Cuándo ponerse en contacto con el soporte técnico

Si sigue teniendo problemas, recopile los siguientes archivos y resultados de comandos y póngase en contacto con el soporte técnico para realizar la clasificación:

[listing]
----
cat /sys/class/scsi_host/host*/nvme_info
/var/log/messages
dmesg
nvme discover output as in:
nvme discover --transport=fc --traddr=nn-0x200a00a098c80f09:pn-0x200b00a098c80f09 --host-traddr=nn-0x20000090fae0ec9d:pn-0x10000090fae0ec9d
nvme list
nvme list-subsys /dev/nvmeXnY
----